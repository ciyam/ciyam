Understanding the File System
-----------------------------

Immediately below the directory where the application server operates is a "files" directory which allows the
application server to function as a file storage system accessible via the standard protocol as well as being
accessible via the peer protocol.

The way this file system operates is quite similar to how "git" operates under the covers and so will be very
familiar to those who have a thorough knowledge of that system. Each file is stored in a directory whose name
is the first two characters of the hex ASCII string of the SHA256 hash of the file content (uncompressed) and
whose filename is the remaining characters of the hash. In order to reduce the disk space footprint files are
normally compressed when they are created (but this behaviour is optional).

Because the name of the file is a secure hash of its content files cannot be edited (as a new version will of
course have a new hash). For both this reason and the fact that SHA256 hashes are not things that most people
could ever hope to remember "tags" can be used for labelling and later locating files.

To see the list and usage of all the file system commands issue the following command from "ciyam_client":

> ? file*

Fundamental File Types
----------------------

The file system supports two fundamental file types which are Blob and List. The first byte of each file will
identify the fundamental file type as well as holding some other flags that will be explained further on.

The Blob file type is used to store any kind of arbitrary data (without any formal meta-data so that it isn't
possible to actually know what kind of data it is that is being stored). The List file type provides a method
of both tying names to other files and constructing a directed acyclic graph of other files through the items
being themselves other List files.

The following illustrates the type, full path and the content of the fundamental files types:

[blob - files/cc/eeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef]
^Ahello

[list - files/02/9eaf5e442ca27b4d9dccba2cd5ace42e7f98ee33c6ab69d19ea55656f1f84a]
^Bcceeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef first

It should be noted that the caret symbol is being used to indicate control characters in the above content so
the actual values of the first character in each of the files above are 0x01 and 0x02 respectively. The above
files can be created using the standard application server protocol with the following commands:

> file_raw -text blob hello
> file_raw -text list "cceeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef first"

The "-text" option is used to prevent file compression which is useful for testing purposes (but not normally
recommended). The "file_info" command can be used to examine the information about a file, and if the file is
a List, to examine the information of referenced files as well.

> file_info -recurse -d=2 029eaf5e442ca27b4d9dccba2cd5ace42e7f98ee33c6ab69d19ea55656f1f84a
[list] 029eaf5e442ca27b4d9dccba2cd5ace42e7f98ee33c6ab69d19ea55656f1f84a (71 B)
first
 [blob] cceeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef (6 B) [utf8]
hello

The above shows the List that had been created contains a single "list item" with the name "first" which then
points to a Blob that contains the text "hello". Considering that any of the "list items" can also themselves
be lists it should be clear that this is extremely flexible, however it is not clear from such an example how
the hash for a particular List (or Blob if desired) could easily be found which brings us to the next feature
of the file system.

File Tags
---------

File "tags" enable the linking of human readible file names to the file hashes in the file system. These tags
function in much the same way as "branch tags" in "git" work. To illustrate how this is useful let's tag just
the List file that was created before.

> file_tag 029eaf5e442ca27b4d9dccba2cd5ace42e7f98ee33c6ab69d19ea55656f1f84a start

Now we can see the same "file info" output we saw above with the following far more user friendly command:

> file_info -recurse -d=2 start
[list] 029eaf5e442ca27b4d9dccba2cd5ace42e7f98ee33c6ab69d19ea55656f1f84a (71 B)
first
 [blob] cceeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef (6 B) [utf8]
hello

A simplified version that doesn't expand the file item content is as follows:

> file_info -recurse start
[list] 029eaf5e442ca27b4d9dccba2cd5ace42e7f98ee33c6ab69d19ea55656f1f84a (71 B)
first
 [blob] cceeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef (6 B)
 ...

So rather than trying to recall "029eaf5e442ca27b4d9dccba2cd5ace42e7f98ee33c6ab69d19ea55656f1f84a" it is only
required to recall "start". So if the List represents a traditional "file name" then imagine that we now want
to rename the "file" named "first" to "greetings".

Firstly we'd create a new List with the following command:

> file_raw -text list "cceeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef greetings"

Then secondly we would switch the "start" tag to the hash of the newly created List as follows:

> file_tag 5a5df977b247df3c493deca2977ce81e7ea4b3451ce393c6cc85cd879864bc58 start

It should also be noted that the tag could have been included in the "file_raw" command with this usage:

> file_raw -text list "cceeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef greetings" start

Now we repeat our List recurse command as follows:

> file_info -recurse start
[list] 5a5df977b247df3c493deca2977ce81e7ea4b3451ce393c6cc85cd879864bc58 (75 B)
greetings
 [blob] cceeb7a985ecc3dabcb4c8f666cd637f16f008e3c963db6aa6f83a7b288c54ef (6 B) [utf8]
 ...

What can be seen here is that the Blob in both the above and previous "list recurse" output is the same which
also means that although we have two List files we actually only have a single file with the "hello" content.
So in this way Blobs can be used with different Lists but disk space is not being wasted as only one file per
"hash" ever exists.

Although only one file per hash exists each file can have multiple tags which can be particularly useful when
identifying things by a specific version or simply as the latest version. To illustrate we'll add two version
specific tags to the two List files we had previously created.

> file_tag 029eaf5e442ca27b4d9dccba2cd5ace42e7f98ee33c6ab69d19ea55656f1f84a start1
> file_tag 5a5df977b247df3c493deca2977ce81e7ea4b3451ce393c6cc85cd879864bc58 start2

To list all of the tags matching a wildcard pattern use the following:

> file_tags start*

and to see the file hash for a specific tag use the following:

> file_hash start

To remove file tags use the "file_tag" command with either the "-remove" or "-unlink" option. If "-unlink" is
used then the file itself will be deleted if no other tags are linked to it whereas the "-remove" option will
only ever remove the tag and will never delete the file that it links to.

Copying Files
-------------

A simple way to copy a file into the file system from the current directory is illustrated as follows:

> file_put ciyam_server.sio xxx

This command will copy the "ciyam_server.sio" configuration file into the file system and create a tag for it
with the name "xxx".

In order to fetch this copy from the file system use the following:

> file_get xxx

It should be noted that the file content (which was originally copied from "ciyam_server.sio") will have been
copied into a file called "xxx" in the current directory (to use a different filename add another argument to
the "file_get" command).

Deleting Files
--------------

For the "xxx" tag created previously the file could be deleted using the "file_tag" command as follows:

> file_tag -unlink xxx

But if any other tags are linked to the same file content then this command will not actually delete the file
therefore to force file deletion the "file_kill" command would instead be used which requires the file's hash
to be first determined from the tag using:

> file_hash xxx
655be670503d269cc190a75b96cfb6fde707b8036c7e2672289c3bfbf30ae669

Then delete the file itself using:

> file_kill 655be670503d269cc190a75b96cfb6fde707b8036c7e2672289c3bfbf30ae669

It should be noted that any tags that were linked to this file will now have been removed but some care would
be advised before deciding to use "file_kill" as this could effectively leave "list" content with now invalid
entries.

File System Statistics
----------------------

The "file_stats" command can be used to see a summary of the file system usage:

> file_stats
[3/1000]152 B/97.7 MiB 3 tag(s)

This indicates that 3 out of a possible 1,000 files are currently stored with 152 bytes of the total capacity
of 97.7 MiB being used with 3 file tags in existence.

There are two settings in "ciyam_server.sio" configuration file that are relevant to the file system and they
are as follows (uncomment and change then restart "ciyam_server" for the new settings to take effect):

# <files_area_item_max_num>1000
# <files_area_item_max_size>100K

It is not recommended to do any changes to the "files" subdirectory directly but if this has occurred then it
is possible to re-synchronise the application server with the following command:

> file_resync

Note that this command's output mimics that of "file_stats" as a way to easily check if changes had occurred.

Core Files
----------

The other flags that were mentioned previously include one flag to indicate if the file is compressed as well
as a flag to indicate that a file is a "core file" and another to indicate that the file is in MIME format.

The "core file" format is a plain text format that begins with a three letter type followed by a colon. After
the colon a header typically follows which consists of comma separated attributes in the form of an attribute
id being assigned a value (e.g. a=123,b=xyz). Some of the core files will include further lines of text which
may or may not be prefixed by a detail type followed by a colon.

Core files (much like configuration files) are essential for the application server so should not be manually
tagged, created or removed (as doing so could risk corrupting application behaviour).

File Archives
-------------

As the file system has a specific limit to the number of files that it allows a file archiving implementation
has been created for storing files that are not currently being used. It should be noted that each archive is
the combination of an external path and information stored about the archive in the server's global ODS DB.

Although disparities between the external file storage and ODS information can be easily fixed direct changes
to the external storage areas are not recommended.

Archive Maintenance
-------------------

The "file_archive" command is used to add/remove/repair or even destroy an archive. The path that you wish to
use for an archive is expected to already exist (i.e. it will not be created) as most often the path would be
a "mount point" or a "drive" (depending upon whether using Linux or Windows).

Assuming the path for the archive is "/mnt/a001", the name chosen for the archive is "001" and it is intended
to hold up to 10MiB of data the create command would be as follows:

file_archive -add /mnt/a001 10MiB 001

To see a list of archives that also displays their last known status use "file_archives". Assuming that there
was no issue with the path (when adding it tests that it can access the path and write to it) then the output
from the "file_archives" command would be as follows:

001 [okay      ] (0 B/10.0 MiB) /mnt/a001

If the path wasn't accessible then you would instead see the following:

001 [bad access] (0 B/10.0 MiB) /mnt/a001

Assuming the issue with the path was then resolved use the "-status_update" option for "file_archives" for it
to re-check that it can access and write to the path. It should be noted that the size that was specified for
the archive creation should be a fair bit less than the physical size of the storage device as the file names
used are sixty four characters each (and typically an OS uses quite a lot more bytes per file as overhead).

If an archive is removed (by using the "-remove" option with the "file_archive" command) then the files which
are already in the archive will remain (only the indexing entries are removed from the global ODS DB). If one
wants to have the archived files removed as well then the "-destroy" option should instead be used. Even when
using "-destroy" it should be noted that the actual path for the archive will not be removed.

If an archive was unintentionally removed or if it is suspected to be in an inconsistent state then "-repair"
can be used to rebuild the ODS DB index of files it contains (this command can take some time to execute when
there are a large number of files in the archive).

It would be recommended to use numbers (maybe use year and month created if starting at "001" as above is not
appealing) so that one can easily see which archives are older. In this way when all of the available storage
space has been nearly exhausted one could destroy the oldest archive to make room for a new one.

Archiving Files
---------------

Typically when a file is stored (that is not a "core file") it will be automatically tagged with a time stamp
prefixed by "ts.". The following is a repeat of the earlier "file_put" but without providing a tag:

file_put ciyam_server.sio

Now if the command "file_tags ts.*" is issued the output would look something like this:

ts.2017032013404998700000000

As the tag is based upon the current time when multiple such tags are found they will be output in order from
oldest to most recently added. This is then used to determine which files to automatically archive (or simply
remove if no archive space is available). Whenever a new file is being added into the file system an existing
file will be archived (and/or removed) if the file system has already stored its maximum number of files.

Files can be manually archived using the "file_relegate" command. Assuming the file system only contained the
tag shown above then assuming an archive with available space exists the following command would archive this
file:

file_relegate -n=1

If more than one archive exists then the first archive (in order of the list of archives) that has sufficient
space will be chosen. Normally if a file is found to have already been archived then it would just be removed
but this can be overridden in a couple of ways. Firstly if the optional archive name argument was provided in
the "file_relegate" then the file will be archived in the named archive even if found to already be stored in
another existing archive. Secondly certain files can appear with "ts.*" tags that have a "!" character suffix
which marks the file as being "important". Assuming more than one archive exists such important files will be
archived in the next archive (in the name order of archives) that they aren't already archived in (supporting
multiple archived copies of the file).

To manually change a file's time stamp tag to become an "important" file first use the "file_hash" command to
retrieve the actual file identity and then issue a "file_tag" command such as follows:

file_tag 7c2cff3b3cf3d9661d55ef770fe1173a54a7e8955c5d655834a602f6cfdae539 ts.2017032013404998700000000*!

Assuming that an important file is retrieved and re-archived several times then if several archives exist the
file should have been arhived in each of these. Thus removing the oldest archive will not prevent these files
from being later retrieved.

Retrieving Archived Files
-------------------------

The command "file_retrieve" will move a file from the archives into the files area. The file's identity which
is the SHA256 "name" must be known in order to retrieve a file from the archives so it this command would not
generally be manually issued. An optional number of days to be added to the current time stamp can be used so
the file might stay in the files area longer than other time stamp tagged files. Instead of this one can pass
the command a specific tag for the file being retrieved which will effectively keep the file from being later
archived. The following command will retrieve the file archived previously giving it the permanent tag "xxx":

file_retrieve 7c2cff3b3cf3d9661d55ef770fe1173a54a7e8955c5d655834a602f6cfdae539 xxx

If no tag is provided then the "ts.<time stamp>" tag will be automatically supplied for the file.

Permanently Deleting All File Copies
------------------------------------

The command "file_relegate" has a "-destroy" option which if used will delete every archived copy of the file
identified as well as remove the file from the files area (if it exists there as well). A "-blacklist" option
can be used instead of the "-destroy" one which will add the hash of the file being removed from the archives
and the files area to a "blacklist" which belongs to the global ODS DB. This will prevent the file from being
later stored via a "file_put" (or "put" for the blockchain peer protocol) into the files area and archives.

